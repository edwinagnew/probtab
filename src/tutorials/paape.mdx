## Pragmatic Armchair Epistemology

## Algorithmic Epistemology?

Imagine sitting comfortably in a deep armchair. You're sat by a crackling fireplace with a pipe in your mouth, philosophising away. You're wondering about wondering about all sorts of wonderful things. You're curious and fascinated by these concepts and thoughts but there's one problem. The thing is that you can't be bothered to get out of your armchair something something

...

The goal of this essay is to explore some surprising connections I've noticed between computability theory and epistemology. The main idea is that the definition of an algorithm accidentally provides a pretty interesting definition of knowledge - not of the real world but knowledge of the *a priori*. 

Let's break it down. Computability theory is about Turing machines and the limits of algorithms. Epistemology is the study of knowledge. *A priori* epistemology is, therefore, the study of knowledge without experience. What's the connection between these two? I imagine there's already alarm bells going off in your head. "Here comes another computer scientist claiming that everything is a computer". Except that's not what I'm claiming! Ironically, we'll see later that traditional epistemology actually assumes we're more like computers than I am. 


### Epistemology

Before we start, I would like to give a brief hommage to knowledge. I think knowledge is fantastic. I am frequently blown away by how much knowledge we as humans have acquired about the world. Some of it is extremely useful - knowing about microorganisms has enabled us to save millions from disease. Some of it is extremely dangerous - knowing about atomic nuclei has enabled us to create nuclear weapons capable of killing billions. Some of it is utterly useless - knowing the first 2 million digits of $\pi$ has allowed us to... But all of it is marvellous. So marvellous I think its worth taking a little step back and asking: what exactly is all this knowledge stuff? Where does it come from? Why are we so good at acquiring it? Wait a second - are we actually any good at acquiring it? What if we're wrong? Oh shit - do we even know anything at all? 

There's a famous quote that says something like "the entire history of Western philosophy can be summarised as a series of footnotes to Plato". Epistemology is probably one of the best examples of this because one day, all the way back in Ancient Greece, Plato was comfortably reclining on an ancient Greek sofa and decided that *knowledge* could be defined as *justified, true belief*. I'll refer to this idea as JTB. In the intervening 2000 years, there has been a tremendous amount of bickering about this definition and not a huge amount of modifications to it. So what are these justified true beliefs? 

The first thing to say is that you probably have a lot of very different connotations of the word "knowledge" and not all of them seem to be directly related to special beliefs. For example, you might think of books or science or google as being the epitome of knowledge. And that's completely fair. So it's worth clarifying that when philosophers talk of defining knowledge, they are usally talking about the questions of the form "what does it mean to say that Alice *knows* that Socrates is mortal" (this is particularly famous example so let's pretend this is what Plato was talking about).  So let's break down, in reverse order.


#### Belief

First things first, for Alice to know something it seems pretty important that she at least believe it. It would be pretty weird for us to credit Alice for knowing something she did not even believe. There's a whole tangent we could take here about what exactly it means for Alice to believe something and all sorts of horrible edge cases to deal with (e.g. whether Alice needs to be certain or whether Alice needs to be consciously aware of her beliefs etc etc). But you should hopefully have a strong intution that belief is necessary for knowledge. For an operational definitin, imagine Alice has been given a test of true or false questions and has decided to tick true for the statement "Socrates is mortal". 

#### Truth

If you've even spoken to anybody, you'll probably have noticed that people have all sorts of beliefs about all sorts of things. And that's great - beliefs are useful for all sorts of things. Good job. But some beliefs are better are than others for the very simple reason that they are wrong. For example, people used to believe that the Earth is flat. This belief was fundamental to astronomical modelling, nautical adventuring and a fair amount of anthropocentrism. If you'd asked these people they would have said that they *knew* that the Earth is flat. However, they didn't. It is now clear to us that they cannot have known this because it turns out that the Earth is *not* flat. However hard you try, you cannot know something that is false. Of course, there are all sorts of reasons you might be interested in false beliefs. But that would make you an agnotologist (the study of ignorance is called [agnotology](https://en.wikipedia.org/wiki/Agnotology)). And right now, we're talking about epistemology.

So to know something it has to be true. This sounds fairly unproblematic. There are, of course, countless bizarre edge cases epistemologists have bickered about (for example - are future events true? What about counter-factuals? What about statements about works of fiction?) but I won't bother with those either.


#### Justification

It's tempting to think that we're done here: surely if Alice beliefs something to be true and it is in fact true, then she knows it? Not quite, according to conventional epistemology. Consider the following example: Alice wakes up one morning with a bad feeling in her bones and decides it's going to rain today. Later that day, it does in fact rain. Did Alice know about the rain? Or perhaps Alice's hair is wet and she concludes that it's raining. Imagine that it is in fact raining, but she was inside a dark room and her hair was wet because she just got out of the shower.


Hopefully these examples make you feel a little uneasy. You'll notice that both cases constitute true knowledge yet unconvinced that Alice *really* knew about the rain. Although she was right, it seems that she was right merely by luck. And there's something about lucky guesses that doesn't feel like they deserve the full status of knowledge. So to have knowledge, say the epistemologists, Alice must not only be right but she must be right for the *right reasons*. They call this justification.

Justification is by far the stickiest part of JTB. This is where most of the bickering happens and has produced the most competing alternatives. But what underlies them all is there needs to be a story of where Alice's (true) belief came from and some specific criteria for this story being a good one. In the examples I just gave, the idea was that neither bad-feeling-in-bones nor wet-because-shower were very good reasons. On the other hand, Alice seeing dark clouds overhead and hearing thunder in the distance are pretty good reasons for believing there may be a spot of rain. I often imagine justification as follows: after filling out the true/false questionnaire, Alice is audited by the council of epistemologists. For each of the statements she answered correctly, they submit her to brutal questioning and only if she passes their standards do they award her the certificate of knowledge. This might sound like the sort of nit-picking that everyone except philosophers finds completely pointless. So allow me to justify the condition of justification a little further (haha), in a few different ways (feel free to skip if you're not interested):

1. My primary school maths teacher always used to bang on about showing my working for my answers. They weren't interested in the right answer, but the right justification. I think they were worried I was copying off my mates or something. So there are at least some situations where the epistemic journey is more important than the destination.

2. As I mentioned at the beginning, knowledge is a pretty neat thing to have - whether because it's useful or just because its kind of cool. So it would be nice to have more of it. So a well explained account of the *process* of acquiring knowledge might help us get better at getting more of it. (unfortunately, this probably also requires epistemologists coming to agreement about what justification is. So far, the footnotes have not converged on this matter)

3. One especially nifty property of knowledge is that it can be shared. I think this is quite a crucial factor in the rapid pace of development of human civilisation relative to the pace of evolution. Anyway, think of a belief that you have that you would have a hard time convincing others. For me, it might be "pasta and pesto is the best meal to make in a jiffy". I really do believe this and yet I've never been able to convince any of my friends of this. After some painful reflection, I've decided this is because I am not able to communicate a good justification for this belief. On the other hand, in the imaginary case I ever get into an argument about whether $2+3=5$, I am confident that whipping out a calculator should settle the dispute without difficulty. This is because calculators are something that we all have access to. My feelings about pesto are not. Though many philosophers would probably disagree with me about this, I reckon that I am unable to access a lot of what goes on in my head, let alone find a coherent way of describing it to you. Yet there are some cases where I am able to take a belief of my own and copy it into your brain (and vice versa - although I guess you'd have to write a rambling blog post and send it to me somehow or something). All jokes aside, the reason I feel obliged to justify the justification condition is I don't expect you to take me on faith that it matters but I do hope that you'll see where I'm coming from after these examples.

So that's some of my justification for the justification condition (sorry if this is all too meta). Please be aware that if you asked two other epistemologists about this, you'd get at least seven reasons they disagree. In the jargon, you'd maybe call my position a social externalism just to show how niche all of this gets. Anyway, if you want to know what the other knowledge nerds think about justification then fuck off and find out yourself (you could try reading [all of this](https://plato.stanford.edu/entries/knowledge-analysis/) - I certainly haven't). To elaborate a little on the controversy, there are two main camps in the bickering about justifcation. I will explain each in the metaphor of the council of epsitemologists:

- *internalism* requires that Alice has some sort of access to her justification or at least that all of the justifcation process occurs *inside* her brain. In other words, Alice must be able to defend herself in front of the council. One particularly optimistic flavour of this is called foundationalism which requires that Alice derive her knowledge from a handful of undoubtable beliefs. So her defense for the mortality of socrates might go something like "your honour, it is part of our consitution that I am justified in believing that all men are mortal. Moreover, it was established in the renowned case of Plato v. Descartes 1700 that I am justified in believing that Socrates was a man. Since the laws of logic are written in our consitution I must be justified in believing that Socrates is mortal".
- *externalism* says that justification includes factors outside of Alice's brain. So Alice does not have to represent herself in front of the council, may be represented by a well-prepared yet impartial legal team. My favourite flavour of externalism is called reliablism which requires that the process of belief formation be generally reliable for that sort of thing (obviously there more precise ways of spelling this out). So in the case of will it rain, Alice's legal team might offer the following defense: "your honour, a psychological evaluation found that Alice's rain belief was formed because she saw the rain clouds. As this graph demonstrates, witnessing rain clouds correctly predicts rain in more than 99% of cases. Thus we deem Alice's belief to be well justified"

As the length of this section relative to the other two shows, justification is a whole mess. Well guess what. It gets worse

import { Accordion } from "react-bootstrap"

<Accordion >
      <Accordion.Item eventKey="0">
        <Accordion.Header>Extended tangent about justification</Accordion.Header>
        <Accordion.Body>
            I'm kind of on a roll writing this and since you're here you must care a little bit for some reason. So with pesto in hand, I want to elaborate on the position I just sketched above because otherwise it looks like I'm hiding behind casual informalities. In umabiguous terms, my claim is as follows: the "real" source of justification is irrelevant. Justification is a social norm for facilitating the communication of true beliefs. 

            From all that I have seen, most externalist theories of justification rely on analysis *the* process of forming *the* belief of interest. I am sceptical that such a unique process exists. I don't know about you, but beliefs just sort of pop into my head as and when I summon them. If I think, "capital of France", then all of a sudden the word "Paris" pops into my head. Let's consider some possible explanations for this appearence:
            1. Evolution conferred advantage of accurate memeories
            2. This is a fact I already knew  
            3. I learnt about the capital of France when I was 6 and have stored that fact in my memeory ever since
            4. My hippocampus sent a signal to my amygdala
            5. Neuron 45 fired which sent a response down synapse 423, which triggered neuron ..., which fired a response in neuron 3282
            6. A certain cluster of calcium ions diffused in a certain way
            7. Something something shrondingers equation

            Can we really say which of these is the correct pathway of belief formation? Even with a much greater neuorscientific understanding of consciousness, surely these differing levels of emergence are equally compatible? Why pick a single one for the existence of the belief? 

            I say: fuck it. Justification is just about reproducing the belief in your brain.


            Actually im confused, what is being communicated if not "the process of justification"?

            What I wanted to say is that how I form beliefs is blahdsf. How you form beliefs if wqerjqw;kler. But communicating justification is when $\exists$ sentence s s.t you hearing $s$ makes your brain go wqerjqw;kler
        </Accordion.Body>
      </Accordion.Item>
</Accordion>

Epistemology: *S* knows $p$ iff:
1. *S* believes $p$.
2. $p$ is true.
3. *S*'s belief in $p$ is justified. 

Computability: $M$ knows $x$ iff $x \in X \iff M(x) = 1$. This breaks down as:
1. $M(x) = 1$.
2. $x \in X$
3. $\forall y \in X, M(y) = 1$. 

The point is that we do not talk of $M$'s knowledge of $x$, but of the whole language $X$. I argue this is a direct analogy to reliabilism: S knows $p$ iff S's process for believing in $p$ is generally accurate. 

Reliabilism